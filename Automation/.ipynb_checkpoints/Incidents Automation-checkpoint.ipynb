{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69ef45a-f53d-49a2-a2af-a9532253944e",
   "metadata": {},
   "source": [
    "### Installing Luigi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daef3348-47d0-4810-8252-419d42fedcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install luigi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab00960a-8dd2-4aa2-81ed-41819f90df07",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3904489-9c78-41f0-b237-f077abefd82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import luigi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import mysql.connector as mysql\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225850e5-8027-4ead-8917-dcc8f0138bad",
   "metadata": {},
   "source": [
    "### Define the connection parameters for MySQL and MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63894e14-4049-4296-8520-6d2eb7267cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MYSQL_HOST = 'localhost'\n",
    "MYSQL_USER = 'root'\n",
    "MYSQL_PASSWORD = 'sana123'\n",
    "MYSQL_DB = 'montgomery'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185f4e06-72d7-41aa-8c5c-b741e9ba24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_uri = \"mongodb+srv://x22237941:sana123@montgomerycluster.tzxvtsd.mongodb.net/?retryWrites=true&w=majority&appName=montgomerycluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e09b7ec-c258-424f-90d1-a0a5ae98f82c",
   "metadata": {},
   "source": [
    "### Importing API librariers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201e386d-6594-4926-a43e-d274139a5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sodapy import Socrata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b7f25f-f12d-48ad-b376-67ec0e4320b3",
   "metadata": {},
   "source": [
    "### Define the task to extract data from the Socrata API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decba58d-67e9-4bbe-b112-2bf2b32d5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractSocrataDataJSON(luigi.Task):\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(\"incidents.json\")\n",
    "    \n",
    "    def run(self):\n",
    "        socrata_domain = 'data.montgomerycountymd.gov'\n",
    "        socrata_dataset_identifier_incidents = 'bhju-22kf'\n",
    "        socrata_token = os.environ.get(\"SODAPY_APPTOKEN\")\n",
    "        client = Socrata(socrata_domain, socrata_token)\n",
    "        results = client.get(socrata_dataset_identifier_incidents)\n",
    "        df = pd.DataFrame.from_dict(results)\n",
    "        incidents_data = df.to_json(orient='records')\n",
    "        with self.output().open('w') as f:\n",
    "            f.write(incidents_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "543e63bc-4572-40ad-9c82-27a64b56736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractSocrataDataCSV(luigi.Task):\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(\"incidents.csv\")  # Output CSV file\n",
    "    \n",
    "    def run(self):\n",
    "        socrata_domain = 'data.montgomerycountymd.gov'\n",
    "        socrata_dataset_identifier_incidents = 'bhju-22kf'\n",
    "        socrata_token = os.environ.get(\"SODAPY_APPTOKEN\")\n",
    "        client = Socrata(socrata_domain, socrata_token)\n",
    "        results = client.get(socrata_dataset_identifier_incidents)\n",
    "        df = pd.DataFrame.from_dict(results)\n",
    "        df.to_csv(self.output().path, index=False)  # Save data to CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9732131a-aa5c-4acf-8c15-551483b3c519",
   "metadata": {},
   "source": [
    "### Define the task to load data into MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eba9c8a-76a7-4d08-904a-56fc62007d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadMySQLData(luigi.Task):\n",
    "    def requires(self):\n",
    "        return ExtractSocrataDataCSV()\n",
    "    \n",
    "    def run(self):\n",
    "        # Define the MySQL connection parameters\n",
    "        host = 'localhost'\n",
    "        user = 'root'\n",
    "        password = 'sana123'\n",
    "        database = 'montgomery2'\n",
    "        \n",
    "        # Define the SQL queries\n",
    "        create_database_query = f\"CREATE DATABASE IF NOT EXISTS {database}\"\n",
    "        use_database_query = f\"USE {database}\"\n",
    "        create_table_query = '''CREATE TABLE IF NOT EXISTS incidents (\n",
    "                                report_number TEXT,\n",
    "                                local_case_number TEXT,\n",
    "                                agency_name TEXT,\n",
    "                                acrs_report_type TEXT,\n",
    "                                crash_date_time TEXT,\n",
    "                                hit_run TEXT,\n",
    "                                route_type TEXT,\n",
    "                                mile_point TEXT,\n",
    "                                mile_point_direction TEXT,\n",
    "                                lane_direction TEXT,\n",
    "                                lane_number TEXT,\n",
    "                                lane_type TEXT,\n",
    "                                number_of_lanes TEXT,\n",
    "                                direction TEXT,\n",
    "                                distance TEXT,\n",
    "                                distance_unit TEXT,\n",
    "                                road_grade TEXT,\n",
    "                                non_traffic TEXT,\n",
    "                                road_name TEXT,\n",
    "                                cross_street_type TEXT,\n",
    "                                cross_street_name TEXT,\n",
    "                                off_road_description TEXT,\n",
    "                                municipality TEXT,\n",
    "                                related_non_motorist TEXT,\n",
    "                                at_fault TEXT,\n",
    "                                collision_type TEXT,\n",
    "                                weather TEXT,\n",
    "                                surface_condition TEXT,\n",
    "                                light TEXT,\n",
    "                                traffic_control TEXT,\n",
    "                                driver_substance_abuse TEXT,\n",
    "                                non_motorist_substance_abuse TEXT,\n",
    "                                first_harmful_event TEXT,\n",
    "                                second_harmful_event TEXT,\n",
    "                                fixed_object_struck TEXT,\n",
    "                                junction TEXT,\n",
    "                                intersection_type TEXT,\n",
    "                                intersection_area TEXT,\n",
    "                                road_alignment TEXT,\n",
    "                                road_condition TEXT,\n",
    "                                road_division TEXT,\n",
    "                                latitude TEXT,\n",
    "                                longitude TEXT,\n",
    "                                location TEXT\n",
    "                                )'''\n",
    "        show_table_query = \"SHOW TABLES\"\n",
    "        drop_columns_query = '''ALTER TABLE incidents\n",
    "                                DROP COLUMN Latitude,\n",
    "                                DROP COLUMN Longitude,\n",
    "                                DROP COLUMN Location'''\n",
    "        insert_data_query = '''INSERT INTO incidents (report_number, local_case_number, agency_name, acrs_report_type, crash_date_time, hit_run, route_type, mile_point, mile_point_direction, lane_direction, lane_number,lane_type, number_of_lanes, direction, distance, distance_unit, road_grade, non_traffic, road_name, cross_street_type, cross_street_name, off_road_description, municipality, related_non_motorist, at_fault, collision_type, weather, surface_condition, light, traffic_control, driver_substance_abuse, non_motorist_substance_abuse, first_harmful_event, second_harmful_event, fixed_object_struck, junction, intersection_type, intersection_area, road_alignment, road_condition, road_division,latitude,longitude,location) VALUES (%s,%s,%s,%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "        # Connect to MySQL database\n",
    "        conn = mysql.connect(host=host, user=user, password=password)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Create database if it does not exist\n",
    "        cursor.execute(create_database_query)\n",
    "\n",
    "        # Use the specified database\n",
    "        cursor.execute(use_database_query)\n",
    "\n",
    "        # Create table if it does not exist\n",
    "        cursor.execute(create_table_query)\n",
    "\n",
    "        # Show tables in the database\n",
    "        cursor.execute(show_table_query)\n",
    "        tables = cursor.fetchall()\n",
    "        for table in tables:\n",
    "            print(table[0])\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        cursor.execute(drop_columns_query)\n",
    "\n",
    "        # Show columns in the table\n",
    "        cursor.execute(\"DESCRIBE incidents\")\n",
    "        columns = cursor.fetchall()\n",
    "        for column in columns:\n",
    "            print(column[0], \"-\", column[1])\n",
    "\n",
    "        # Insert data into the table\n",
    "        df = pd.read_csv(self.input().path)\n",
    "        df_filled = df.fillna(\"Missing\")\n",
    "        inserted_records_count = 0\n",
    "        for index, row in df_filled.iterrows():\n",
    "            cursor.execute(insert_data_query, tuple(row))\n",
    "            inserted_records_count += 1\n",
    "        conn.commit()\n",
    "        print(\"Number of records inserted into the incidents table:\", inserted_records_count)\n",
    "\n",
    "        #Check the count of inserted data\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM incidents\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        print(\"Number of records in 'incidents' table:\", count)\n",
    "\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40136a8c-d7c2-43ec-92eb-3c701f53611a",
   "metadata": {},
   "source": [
    "### Define the transformation task using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8b8e416-3649-41de-965c-1d3ca2ce4413",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformData(luigi.Task):\n",
    "    def requires(self):\n",
    "        return ExtractMySQLData()\n",
    "    \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(\"transformed_data.json\")  # Output file\n",
    "    \n",
    "    def run(self):\n",
    "        # Define the MySQL connection parameters\n",
    "        host = 'localhost'\n",
    "        user = 'root'\n",
    "        password = 'sana123'\n",
    "        database = 'montgomery2'\n",
    "\n",
    "        # Define the SQL query to read data\n",
    "        read_data_query = \"SELECT * FROM incident_dupe\"\n",
    "\n",
    "        # Connect to MySQL database\n",
    "        conn = mysql.connect(host=host, user=user, password=password, database=database)\n",
    "\n",
    "        # Read data from MySQL into a DataFrame\n",
    "        sql_frame = pd.read_sql(read_data_query, conn)\n",
    "\n",
    "        # Checking for duplicate records\n",
    "        duplicate_rows = sql_frame.duplicated()\n",
    "        print(\"Number of duplicate rows:\", duplicate_rows.sum())\n",
    "        print(\"--------------------------------------------------\")\n",
    "        # Checking Missing Values\n",
    "        missing_values = sql_frame.isnull().sum()\n",
    "        print(\"Columns with missing values:\")\n",
    "        print(missing_values)\n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "        # Handle 'Missing' values\n",
    "        sql_frame['hit_run'] = sql_frame['hit_run'].replace('Missing', 'unknown')\n",
    "        sql_frame['direction'] = sql_frame['direction'].replace('Missing', 'Unknown')\n",
    "        sql_frame['mile_point'] = sql_frame['mile_point'].replace('Missing', np.nan).astype(float)\n",
    "        sql_frame['mile_point'].fillna(sql_frame['mile_point'].median(), inplace=True)\n",
    "        sql_frame['distance'] = sql_frame['distance'].replace('Missing', np.nan).astype(float)\n",
    "        sql_frame['distance'].fillna(sql_frame['distance'].median(), inplace=True)\n",
    "        sql_frame['lane_direction'] = sql_frame['lane_direction'].replace('Missing', sql_frame['lane_direction'].mode()[0])\n",
    "\n",
    "        # Drop specified columns\n",
    "        columns_to_drop = ['cross_street_type', 'off_road_description', 'municipality', 'first_harmful_event', 'second_harmful_event', \n",
    "                           'mile_point_direction', 'road_grade', 'non_traffic', 'fixed_object_struck', 'intersection_area', 'road_division']\n",
    "        sql_frame.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "        # Filter out columns with too many 'Missing' values\n",
    "        threshold = 50000\n",
    "        columns_to_drop = [column for column, count in missing_values.items() if count > threshold]\n",
    "        sql_frame.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "        # Print the remaining columns\n",
    "        print(\"Remaining columns after dropping:\")\n",
    "        print(sql_frame.columns.tolist())\n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "        # Save the transformed DataFrame to JSON\n",
    "        filename = \"transformed_data.json\"\n",
    "        sql_frame.to_json(filename, orient='records')\n",
    "\n",
    "        # Close MySQL connection\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51e081-b344-49c9-8b46-0137e94f74ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
