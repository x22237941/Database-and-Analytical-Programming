{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69ef45a-f53d-49a2-a2af-a9532253944e",
   "metadata": {},
   "source": [
    "### Installing Luigi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daef3348-47d0-4810-8252-419d42fedcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install luigi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab00960a-8dd2-4aa2-81ed-41819f90df07",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3904489-9c78-41f0-b237-f077abefd82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import mysql.connector as mysql\n",
    "from sqlalchemy import create_engine\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "import luigi\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225850e5-8027-4ead-8917-dcc8f0138bad",
   "metadata": {},
   "source": [
    "### Define the connection parameters for MySQL and MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63894e14-4049-4296-8520-6d2eb7267cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MYSQL_HOST = 'localhost'\n",
    "MYSQL_USER = 'root'\n",
    "MYSQL_PASSWORD = 'sana123'\n",
    "MYSQL_DB = 'montgomery'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185f4e06-72d7-41aa-8c5c-b741e9ba24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_uri = \"mongodb+srv://x22237941:sana123@montgomerycluster.tzxvtsd.mongodb.net/?retryWrites=true&w=majority&appName=montgomerycluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e09b7ec-c258-424f-90d1-a0a5ae98f82c",
   "metadata": {},
   "source": [
    "### Importing API librariers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201e386d-6594-4926-a43e-d274139a5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sodapy import Socrata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b7f25f-f12d-48ad-b376-67ec0e4320b3",
   "metadata": {},
   "source": [
    "### Define the task to extract data from the Socrata API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decba58d-67e9-4bbe-b112-2bf2b32d5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractSocrataDataJSON(luigi.Task):\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(\"incidents.json\")\n",
    "    \n",
    "    def run(self):\n",
    "        socrata_domain = 'data.montgomerycountymd.gov'\n",
    "        socrata_dataset_identifier_incidents = 'bhju-22kf'\n",
    "        socrata_token = os.environ.get(\"SODAPY_APPTOKEN\")\n",
    "        client = Socrata(socrata_domain, socrata_token)\n",
    "        results = client.get(socrata_dataset_identifier_incidents)\n",
    "        df = pd.DataFrame.from_dict(results)\n",
    "        incidents_data = df.to_json(orient='records')\n",
    "        with self.output().open('w') as f:\n",
    "            f.write(incidents_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543e63bc-4572-40ad-9c82-27a64b56736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractSocrataDataCSV(luigi.Task):\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(\"incidents.csv\")  # Output CSV file\n",
    "    \n",
    "    def run(self):\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        print(\"Currently ExtractSocrataDataCSV is in progress\")\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        socrata_domain = 'data.montgomerycountymd.gov'\n",
    "        socrata_dataset_identifier_incidents = 'bhju-22kf'\n",
    "        socrata_token = os.environ.get(\"SODAPY_APPTOKEN\")\n",
    "        client = Socrata(socrata_domain, socrata_token)\n",
    "        results = client.get(socrata_dataset_identifier_incidents)\n",
    "        df = pd.DataFrame.from_dict(results)\n",
    "        df.head()\n",
    "        # Use the filter method to select columns that don't start with \":@\"\n",
    "        filtered_columns = df.filter(regex=\"^:@\", axis=1)\n",
    "        columns_to_drop = ['latitude', 'longitude','geolocation']\n",
    "        # Drop the selected columns\n",
    "        df.drop(filtered_columns, axis=1, inplace=True)\n",
    "        df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "        df.to_csv(self.output().path, index=False)  # Save data to CSV file\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        print(\"ExtractSocrataDataCSV Finished Successfully\")\n",
    "        print(\"-----------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9732131a-aa5c-4acf-8c15-551483b3c519",
   "metadata": {},
   "source": [
    "### Define the task to load data into MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eba9c8a-76a7-4d08-904a-56fc62007d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadMySQLData(luigi.Task):\n",
    "    def requires(self):\n",
    "        return ExtractSocrataDataCSV()\n",
    "    \n",
    "    def run(self):\n",
    "        # Define the MySQL connection parameters\n",
    "        host = 'localhost'\n",
    "        user = 'root'\n",
    "        password = 'sana123'\n",
    "        database = 'montgomery2'\n",
    "        \n",
    "        # Define the SQL queries\n",
    "        create_database_query = f\"CREATE DATABASE IF NOT EXISTS {database}\"\n",
    "        use_database_query = f\"USE {database}\"\n",
    "        create_table_query = '''CREATE TABLE IF NOT EXISTS incidents (\n",
    "                                report_number TEXT,\n",
    "                                local_case_number TEXT,\n",
    "                                agency_name TEXT,\n",
    "                                acrs_report_type TEXT,\n",
    "                                crash_date_time TEXT,\n",
    "                                hit_run TEXT,\n",
    "                                lane_number TEXT,\n",
    "                                number_of_lanes TEXT,\n",
    "                                non_traffic TEXT,\n",
    "                                off_road_description TEXT,\n",
    "                                at_fault TEXT,\n",
    "                                collision_type TEXT,\n",
    "                                weather TEXT,\n",
    "                                light TEXT,\n",
    "                                traffic_control TEXT,\n",
    "                                driver_substance_abuse TEXT,\n",
    "                                first_harmful_event TEXT,\n",
    "                                second_harmful_event TEXT,\n",
    "                                fixed_object_struck TEXT,\n",
    "                                route_type TEXT,\n",
    "                                mile_point TEXT,\n",
    "                                mile_point_direction TEXT,\n",
    "                                lane_direction TEXT,\n",
    "                                direction TEXT,\n",
    "                                distance TEXT,\n",
    "                                distance_unit TEXT,\n",
    "                                road_grade TEXT,\n",
    "                                road_name TEXT,\n",
    "                                cross_street_type TEXT,\n",
    "                                cross_street_name TEXT,\n",
    "                                municipality TEXT,\n",
    "                                surface_condition TEXT,\n",
    "                                junction TEXT,\n",
    "                                intersection_type TEXT,\n",
    "                                intersection_area TEXT,\n",
    "                                road_alignment TEXT,\n",
    "                                road_condition TEXT,\n",
    "                                road_division TEXT,\n",
    "                                related_non_motorist TEXT,\n",
    "                                non_motorist_substance_abuse TEXT,\n",
    "                                lane_type TEXT\n",
    "                                )'''\n",
    "        show_table_query = \"SHOW TABLES\"\n",
    "        drop_columns_query = '''ALTER TABLE incidents\n",
    "                                DROP COLUMN latitude,\n",
    "                                DROP COLUMN longitude,\n",
    "                                DROP COLUMN location'''\n",
    "        insert_data_query = '''INSERT INTO incidents (report_number, local_case_number, agency_name, acrs_report_type, crash_date_time, hit_run, lane_number, number_of_lanes, non_traffic, off_road_description, at_fault,collision_type, weather, light, traffic_control, driver_substance_abuse, first_harmful_event, second_harmful_event, fixed_object_struck, route_type, mile_point, mile_point_direction, lane_direction, direction, distance, distance_unit, road_grade, road_name, cross_street_type, cross_street_name, municipality, surface_condition, junction, intersection_type, intersection_area, road_alignment, road_condition, road_division,related_non_motorist,non_motorist_substance_abuse,lane_type) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        print(\"Currently LoadMySQLData is in progress\")\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        # Connect to MySQL database\n",
    "        conn = mysql.connect(host=host, user=user, password=password)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Create database if it does not exist\n",
    "        cursor.execute(create_database_query)\n",
    "\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        print(\"Database created successfully\")\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        \n",
    "        # Use the specified database\n",
    "        cursor.execute(use_database_query)\n",
    "\n",
    "        #df = pd.read_csv(self.input().path)\n",
    "        #read csv file and create a table structure\n",
    "        df = pd.read_csv('incidents.csv')\n",
    "        print(df.dtypes)\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "\n",
    "        # Set default data type for columns\n",
    "        default_dtype = 'TEXT'\n",
    "        # Create column definitions for SQL table\n",
    "        columns = [f\"{col} {default_dtype}\" for col in df.columns]\n",
    "        table_name = 'incidents'\n",
    "        create_table_sql = f\"CREATE TABLE {table_name} ({', '.join(columns)});\"\n",
    "\n",
    "        # Create table if it does not exist\n",
    "        cursor.execute(create_table_sql)\n",
    "\n",
    "        # Show tables in the database\n",
    "        cursor.execute(show_table_query)\n",
    "        tables = cursor.fetchall()\n",
    "        for table in tables:\n",
    "            print(table[0])\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "\n",
    "        # Show columns in the table\n",
    "        cursor.execute(\"DESCRIBE incidents\")\n",
    "        columns = cursor.fetchall()\n",
    "        for column in columns:\n",
    "            print(column[0], \"-\", column[1])\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "\n",
    "        #Insert statement built\n",
    "        # Construct the INSERT statement\n",
    "        table_name = 'incidents'\n",
    "        columns = ', '.join(df.columns)\n",
    "        placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "        insert_statement = '''INSERT INTO incidents ({columns}) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "        # Convert DataFrame to list of tuples (each tuple representing a row)\n",
    "        #rows = [tuple(row) for row in df.values]\n",
    "\n",
    "        # Execute the INSERT statement\n",
    "        #cursor.executemany(insert_statement, rows)\n",
    "\n",
    "        # Insert data into the table\n",
    "        df_filled = df.fillna(\"Missing\")\n",
    "        df_filled.astype(str)\n",
    "        inserted_records_count = 0\n",
    "        for index, row in df_filled.iterrows():\n",
    "            #cursor.execute(insert_data_query, tuple(row))\n",
    "            cursor.execute(insert_statement, tuple(row))\n",
    "            inserted_records_count += 1\n",
    "        conn.commit()\n",
    "        print(\"Number of records inserted into the incidents table:\", inserted_records_count)\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        print(\"Records inserted successfully\")\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "\n",
    "        #Check the count of inserted data\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM incidents\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        print(\"Number of records in 'incidents' table:\", count)\n",
    "\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        print(\"LoadMySQLData finished successfully\")\n",
    "        print(\"-----------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40136a8c-d7c2-43ec-92eb-3c701f53611a",
   "metadata": {},
   "source": [
    "### Define the transformation task using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8b8e416-3649-41de-965c-1d3ca2ce4413",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformData(luigi.Task):\n",
    "    def requires(self):\n",
    "        return LoadMySQLData()\n",
    "    \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(\"transformed_data.json\")  # Output file\n",
    "    \n",
    "    def run(self):\n",
    "\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        print(\"TransformData is in progress and reading data from MySQL\")\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "\n",
    "        # Define the MySQL connection parameters\n",
    "        host = 'localhost'\n",
    "        user = 'root'\n",
    "        password = 'sana123'\n",
    "        database = 'montgomery2'\n",
    "\n",
    "        # Define the SQL query to read data\n",
    "        read_data_query = \"SELECT * FROM incidents\"\n",
    "\n",
    "        # Connect to MySQL database\n",
    "        conn = mysql.connect(host=host, user=user, password=password, database=database)\n",
    "        \n",
    "        # Read data from MySQL into a DataFrame\n",
    "        sql_frame = pd.read_sql(read_data_query, conn)\n",
    "\n",
    "        # Checking for duplicate records\n",
    "        duplicate_rows = sql_frame.duplicated()\n",
    "        print(\"Number of duplicate rows:\", duplicate_rows.sum())\n",
    "        print(\"--------------------------------------------------\")\n",
    "        # Checking Missing Values\n",
    "        missing_values = sql_frame.isnull().sum()\n",
    "        print(\"Columns with missing values:\")\n",
    "        print(missing_values)\n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "        # Handle 'Missing' values\n",
    "        sql_frame['hit_run'] = sql_frame['hit_run'].replace('Missing', 'unknown')\n",
    "        sql_frame['direction'] = sql_frame['direction'].replace('Missing', 'Unknown')\n",
    "        sql_frame['mile_point'] = sql_frame['mile_point'].replace('Missing', np.nan).astype(float)\n",
    "        sql_frame['mile_point'].fillna(sql_frame['mile_point'].median(), inplace=True)\n",
    "        sql_frame['distance'] = sql_frame['distance'].replace('Missing', np.nan).astype(float)\n",
    "        sql_frame['distance'].fillna(sql_frame['distance'].median(), inplace=True)\n",
    "        sql_frame['lane_direction'] = sql_frame['lane_direction'].replace('Missing', sql_frame['lane_direction'].mode()[0])\n",
    "\n",
    "        # Drop specified columns\n",
    "        columns_to_drop = ['off_road_description', 'first_harmful_event', 'second_harmful_event', 'related_non_motorist', 'non_motorist_substance_abuse','lane_type','mile_point_direction', 'road_grade', 'non_traffic', 'fixed_object_struck', 'intersection_area', 'road_division']\n",
    "        sql_frame.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "        # Print the remaining columns\n",
    "        print(\"Remaining columns after dropping:\")\n",
    "        print(sql_frame.columns.tolist())\n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "        # Save the transformed DataFrame to JSON\n",
    "        filename = \"transformed_data.json\"\n",
    "        sql_frame.to_json(filename, orient='records')\n",
    "\n",
    "        # Close MySQL connection\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98773cd1-3d26-4341-81ed-78d664a451da",
   "metadata": {},
   "source": [
    "### Define the MongoDB task to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a51767f-f92d-4362-a8c6-0d4151b0beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadMongoDBData(luigi.Task):\n",
    "    def requires(self):\n",
    "        return TransformData()\n",
    "    \n",
    "    def run(self):\n",
    "        # MongoDB connection URI\n",
    "        uri = \"mongodb+srv://x22237941:sana123@montgomerycluster.tzxvtsd.mongodb.net/?retryWrites=true&w=majority&appName=montgomerycluster\"\n",
    "\n",
    "        # Create a new client and connect to the server\n",
    "        client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "        try:\n",
    "            # Ping the MongoDB deployment\n",
    "            client.montgomery.command('ping')\n",
    "            print(\"Pinged the MongoDB deployment. Successfully connected to MongoDB!\")\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "        try:\n",
    "            # Check server status\n",
    "            server_status = client.montgomery.command('serverStatus')\n",
    "            print(\"Server is up and running.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "        # List databases\n",
    "        databases = client.list_database_names()\n",
    "        print(\"Databases:\")\n",
    "        for db_obj in databases:\n",
    "            print(db_obj)\n",
    "\n",
    "        # Select database and collection\n",
    "        database_name = \"montgomery\"\n",
    "        db = client[database_name]\n",
    "\n",
    "        # List collections in the selected database\n",
    "        collections = db.list_collection_names()\n",
    "        print(\"\\nCollections in\", database_name, \":\")\n",
    "        for col in collections:\n",
    "            print(col)\n",
    "\n",
    "        # Load JSON file\n",
    "        filename = \"transformed_data.json\"\n",
    "        with open(filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # Insert documents into collection\n",
    "        collection_name = 'incidents'  # assuming collection name is 'incidents'\n",
    "        collection = db[collection_name]\n",
    "        collection.insert_many(data)\n",
    "        print(\"JSON data successfully loaded into MongoDB collection 'incidents' in database 'montgomery'.\")\n",
    "\n",
    "        # Get the total number of documents in the collection\n",
    "        total_records = collection.count_documents({})\n",
    "        print(\"Total number of records in the collection:\", total_records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e24f63-ad0c-4a2c-9d95-9e9c7c5def24",
   "metadata": {},
   "source": [
    "### Define the main task to run the ETL pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c55b968b-274a-4e29-abd3-782019a8c663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if ETLPipeline() is complete\n",
      "C:\\Users\\SANA JALGAONKAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\luigi\\worker.py:426: UserWarning: Task ETLPipeline() without outputs has no custom complete() method\n",
      "  is_complete = task.complete()\n",
      "DEBUG: Checking if LoadMongoDBData() is complete\n",
      "C:\\Users\\SANA JALGAONKAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\luigi\\worker.py:426: UserWarning: Task LoadMongoDBData() without outputs has no custom complete() method\n",
      "  is_complete = task.complete()\n",
      "INFO: Informed scheduler that task   ETLPipeline__99914b932b   has status   PENDING\n",
      "DEBUG: Checking if TransformData() is complete\n",
      "INFO: Informed scheduler that task   LoadMongoDBData__99914b932b   has status   PENDING\n",
      "DEBUG: Checking if LoadMySQLData() is complete\n",
      "C:\\Users\\SANA JALGAONKAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\luigi\\worker.py:426: UserWarning: Task LoadMySQLData() without outputs has no custom complete() method\n",
      "  is_complete = task.complete()\n",
      "INFO: Informed scheduler that task   TransformData__99914b932b   has status   PENDING\n",
      "DEBUG: Checking if ExtractSocrataDataCSV() is complete\n",
      "INFO: Informed scheduler that task   LoadMySQLData__99914b932b   has status   PENDING\n",
      "INFO: Informed scheduler that task   ExtractSocrataDataCSV__99914b932b   has status   PENDING\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 5\n",
      "INFO: [pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) running   ExtractSocrataDataCSV()\n",
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------\n",
      "Currently ExtractSocrataDataCSV is in progress\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) done      ExtractSocrataDataCSV()\n",
      "INFO:luigi-interface:[pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) done      ExtractSocrataDataCSV()\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "DEBUG:luigi-interface:1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   ExtractSocrataDataCSV__99914b932b   has status   DONE\n",
      "INFO:luigi-interface:Informed scheduler that task   ExtractSocrataDataCSV__99914b932b   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG:luigi-interface:Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 4\n",
      "DEBUG:luigi-interface:Pending tasks: 4\n",
      "INFO: [pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) running   LoadMySQLData()\n",
      "INFO:luigi-interface:[pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) running   LoadMySQLData()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------\n",
      "ExtractSocrataDataCSV Finished Successfully\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "Currently LoadMySQLData is in progress\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "Database created successfully\n",
      "-----------------------------------------------------------------------------\n",
      "report_number                    object\n",
      "local_case_number                 int64\n",
      "agency_name                      object\n",
      "acrs_report_type                 object\n",
      "crash_date_time                  object\n",
      "hit_run                          object\n",
      "lane_number                       int64\n",
      "number_of_lanes                   int64\n",
      "nontraffic                       object\n",
      "off_road_description             object\n",
      "at_fault                         object\n",
      "collision_type                   object\n",
      "weather                          object\n",
      "light                            object\n",
      "traffic_control                  object\n",
      "driver_substance_abuse           object\n",
      "first_harmful_event              object\n",
      "second_harmful_event             object\n",
      "fixed_oject_struck               object\n",
      "route_type                       object\n",
      "mile_point                      float64\n",
      "mile_point_direction             object\n",
      "lane_direction                   object\n",
      "direction                        object\n",
      "distance                        float64\n",
      "distance_unit                    object\n",
      "road_grade                       object\n",
      "road_name                        object\n",
      "cross_street_type                object\n",
      "cross_street_name                object\n",
      "municipality                     object\n",
      "surface_condition                object\n",
      "junction                         object\n",
      "intersection_type                object\n",
      "intersection_area                object\n",
      "road_alignment                   object\n",
      "road_condition                   object\n",
      "road_division                    object\n",
      "related_non_motorist             object\n",
      "non_motorist_substance_abuse     object\n",
      "lane_type                        object\n",
      "dtype: object\n",
      "-----------------------------------------------------------------------------\n",
      "incidents\n",
      "-----------------------------------------------------------------------------\n",
      "report_number - text\n",
      "local_case_number - text\n",
      "agency_name - text\n",
      "acrs_report_type - text\n",
      "crash_date_time - text\n",
      "hit_run - text\n",
      "lane_number - text\n",
      "number_of_lanes - text\n",
      "nontraffic - text\n",
      "off_road_description - text\n",
      "at_fault - text\n",
      "collision_type - text\n",
      "weather - text\n",
      "light - text\n",
      "traffic_control - text\n",
      "driver_substance_abuse - text\n",
      "first_harmful_event - text\n",
      "second_harmful_event - text\n",
      "fixed_oject_struck - text\n",
      "route_type - text\n",
      "mile_point - text\n",
      "mile_point_direction - text\n",
      "lane_direction - text\n",
      "direction - text\n",
      "distance - text\n",
      "distance_unit - text\n",
      "road_grade - text\n",
      "road_name - text\n",
      "cross_street_type - text\n",
      "cross_street_name - text\n",
      "municipality - text\n",
      "surface_condition - text\n",
      "junction - text\n",
      "intersection_type - text\n",
      "intersection_area - text\n",
      "road_alignment - text\n",
      "road_condition - text\n",
      "road_division - text\n",
      "related_non_motorist - text\n",
      "non_motorist_substance_abuse - text\n",
      "lane_type - text\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) done      LoadMySQLData()\n",
      "INFO:luigi-interface:[pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) done      LoadMySQLData()\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "DEBUG:luigi-interface:1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   LoadMySQLData__99914b932b   has status   DONE\n",
      "INFO:luigi-interface:Informed scheduler that task   LoadMySQLData__99914b932b   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG:luigi-interface:Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 3\n",
      "DEBUG:luigi-interface:Pending tasks: 3\n",
      "INFO: [pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) running   TransformData()\n",
      "INFO:luigi-interface:[pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) running   TransformData()\n",
      "C:\\Users\\SANA JALGAONKAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\luigi\\worker.py:426: UserWarning: Task LoadMySQLData() without outputs has no custom complete() method\n",
      "  is_complete = task.complete()\n",
      "ERROR: [pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) failed    TransformData()\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SANA JALGAONKAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\luigi\\worker.py\", line 195, in run\n",
      "    raise RuntimeError('Unfulfilled %s at run time: %s' % (deps, ', '.join(missing)))\n",
      "RuntimeError: Unfulfilled dependency at run time: LoadMySQLData__99914b932b\n",
      "ERROR:luigi-interface:[pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) failed    TransformData()\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SANA JALGAONKAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\luigi\\worker.py\", line 195, in run\n",
      "    raise RuntimeError('Unfulfilled %s at run time: %s' % (deps, ', '.join(missing)))\n",
      "RuntimeError: Unfulfilled dependency at run time: LoadMySQLData__99914b932b\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "DEBUG:luigi-interface:1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   TransformData__99914b932b   has status   FAILED\n",
      "INFO:luigi-interface:Informed scheduler that task   TransformData__99914b932b   has status   FAILED\n",
      "DEBUG: Checking if TransformData() is complete\n",
      "DEBUG:luigi-interface:Checking if TransformData() is complete\n",
      "DEBUG: Checking if LoadMySQLData() is complete\n",
      "DEBUG:luigi-interface:Checking if LoadMySQLData() is complete\n",
      "INFO: Informed scheduler that task   TransformData__99914b932b   has status   PENDING\n",
      "INFO:luigi-interface:Informed scheduler that task   TransformData__99914b932b   has status   PENDING\n",
      "DEBUG: Checking if ExtractSocrataDataCSV() is complete\n",
      "DEBUG:luigi-interface:Checking if ExtractSocrataDataCSV() is complete\n",
      "INFO: Informed scheduler that task   LoadMySQLData__99914b932b   has status   PENDING\n",
      "INFO:luigi-interface:Informed scheduler that task   LoadMySQLData__99914b932b   has status   PENDING\n",
      "INFO: Informed scheduler that task   ExtractSocrataDataCSV__99914b932b   has status   DONE\n",
      "INFO:luigi-interface:Informed scheduler that task   ExtractSocrataDataCSV__99914b932b   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG:luigi-interface:Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 3\n",
      "DEBUG:luigi-interface:Pending tasks: 3\n",
      "INFO: [pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) running   TransformData()\n",
      "INFO:luigi-interface:[pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) running   TransformData()\n",
      "ERROR: [pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) failed    TransformData()\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SANA JALGAONKAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\luigi\\worker.py\", line 195, in run\n",
      "    raise RuntimeError('Unfulfilled %s at run time: %s' % (deps, ', '.join(missing)))\n",
      "RuntimeError: Unfulfilled dependency at run time: LoadMySQLData__99914b932b\n",
      "ERROR:luigi-interface:[pid 31652] Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) failed    TransformData()\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SANA JALGAONKAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\luigi\\worker.py\", line 195, in run\n",
      "    raise RuntimeError('Unfulfilled %s at run time: %s' % (deps, ', '.join(missing)))\n",
      "RuntimeError: Unfulfilled dependency at run time: LoadMySQLData__99914b932b\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "DEBUG:luigi-interface:1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   TransformData__99914b932b   has status   FAILED\n",
      "INFO:luigi-interface:Informed scheduler that task   TransformData__99914b932b   has status   FAILED\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG:luigi-interface:Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG:luigi-interface:Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "DEBUG:luigi-interface:There are no more tasks to run at this time\n",
      "DEBUG: There are 3 pending tasks possibly being run by other workers\n",
      "DEBUG:luigi-interface:There are 3 pending tasks possibly being run by other workers\n",
      "DEBUG: There are 3 pending tasks unique to this worker\n",
      "DEBUG:luigi-interface:There are 3 pending tasks unique to this worker\n",
      "DEBUG: There are 3 pending tasks last scheduled by this worker\n",
      "DEBUG:luigi-interface:There are 3 pending tasks last scheduled by this worker\n",
      "INFO: Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) was stopped. Shutting down Keep-Alive thread\n",
      "INFO:luigi-interface:Worker Worker(salt=5528197975, workers=1, host=LAPTOP-JCBDQEO9, username=SANA JALGAONKAR, pid=31652) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 5 tasks of which:\n",
      "* 2 ran successfully:\n",
      "    - 1 ExtractSocrataDataCSV()\n",
      "    - 1 LoadMySQLData()\n",
      "* 1 failed:\n",
      "    - 1 TransformData()\n",
      "* 2 were left pending, among these:\n",
      "    * 2 had failed dependencies:\n",
      "        - 1 ETLPipeline()\n",
      "        - 1 LoadMongoDBData()\n",
      "\n",
      "This progress looks :( because there were failed tasks\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "INFO:luigi-interface:\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 5 tasks of which:\n",
      "* 2 ran successfully:\n",
      "    - 1 ExtractSocrataDataCSV()\n",
      "    - 1 LoadMySQLData()\n",
      "* 1 failed:\n",
      "    - 1 TransformData()\n",
      "* 2 were left pending, among these:\n",
      "    * 2 had failed dependencies:\n",
      "        - 1 ETLPipeline()\n",
      "        - 1 LoadMongoDBData()\n",
      "\n",
      "This progress looks :( because there were failed tasks\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records inserted into the incidents table: 1000\n",
      "-----------------------------------------------------------------------------\n",
      "Records inserted successfully\n",
      "-----------------------------------------------------------------------------\n",
      "Number of records in 'incidents' table: 1000\n",
      "-----------------------------------------------------------------------------\n",
      "LoadMySQLData finished successfully\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class ETLPipeline(luigi.Task):\n",
    "    def requires(self):\n",
    "        return LoadMongoDBData()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    luigi.build([ETLPipeline()], local_scheduler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5b433e-ea86-4461-a35d-85245ce9f3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
